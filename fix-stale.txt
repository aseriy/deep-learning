Yes—your “staleness fixer” should:

Work off the latest epoch, not per-centroid.

For each stale row, recompute the nearest centroid among the current epoch’s centroids, then write a fresh mapping for the current epoch.

Here’s a concise, set-based way to do it in CRDB (no canvas changes):

-- 1) Find the current epoch
WITH cur AS (
  SELECT max(epoch) AS epoch FROM public.passage_passage_vector_centroid
),

-- 2) Pick a batch of stale rows (any pid whose latest mapping predates current epoch)
stale AS (
  SELECT c.pid
  FROM public.passage_passage_vector_clusters AS c, cur
  WHERE c.epoch < cur.epoch
  GROUP BY c.pid
  LIMIT 1000  -- tune batch size
),

-- 3) Fetch their vectors
vecs AS (
  SELECT s.pid, s.passage_vector
  FROM public.passage AS s
  JOIN stale USING (pid)
),

-- 4) For each vector, choose the nearest centroid from the current epoch
assign AS (
  SELECT
    v.pid,
    (SELECT ce.id
     FROM public.passage_passage_vector_centroid AS ce, cur
     WHERE ce.epoch = cur.epoch
     ORDER BY ce.centroid <-> v.passage_vector ASC
     LIMIT 1) AS cluster_id
  FROM vecs AS v
)

-- 5) Upsert the new mapping for the current epoch
UPSERT INTO public.passage_passage_vector_clusters (pid, epoch, cluster_id)
SELECT a.pid, cur.epoch, a.cluster_id
FROM assign AS a, cur;


Notes:

This re-associates stale rows to the closest centroid of the current epoch (not necessarily the same centroid as before).

Because your PK is (pid, epoch), the UPSERT will insert or overwrite the row for the current epoch, leaving historical epochs intact.

Run this periodically or after every N centroid updates; adjust the LIMIT for batching.



-- Inputs (substitute your names)
--   base table:        {table}                with columns: {pk}, {column} (vector)
--   centroids table:   {table}_{column}_centroid   (epoch, id, centroid)
--   clusters table:    {table}_{column}_clusters   (pid, epoch, cluster_id)

WITH latest AS (
  SELECT max(epoch) AS e FROM {table}_{column}_centroid
)
UPSERT INTO {table}_{column}_clusters (pid, epoch, cluster_id)
SELECT s.{pk} AS pid,
       l.e     AS epoch,
       c.id    AS cluster_id
FROM {table} AS s
CROSS JOIN latest AS l
JOIN LATERAL (
  SELECT id
  FROM {table}_{column}_centroid
  WHERE epoch = l.e
  ORDER BY l2_distance(s.{column}, centroid)  -- or cosine_distance / inner_product
  LIMIT 1
) AS c ON true;




-- Inputs (substitute your names)
--   base table:        {table}                with columns: {pk}, {column} (vector)
--   centroids table:   {table}_{column}_centroid   (epoch, id, centroid)
--   clusters table:    {table}_{column}_clusters   (pid, epoch, cluster_id)

WITH latest AS (
  SELECT max(epoch) AS e FROM passage_passage_vector_centroid
)
UPSERT INTO passage_passage_vector_clusters (pid, epoch, cluster_id)
SELECT s.pid AS pid,
       l.e     AS epoch,
       c.id    AS cluster_id
FROM passage AS s
CROSS JOIN latest AS l
JOIN LATERAL (
  SELECT id
  FROM passage_passage_vector_centroid
  WHERE epoch = l.e
  ORDER BY l2_distance(s.passage_vector, centroid)  -- or cosine_distance / inner_product
  LIMIT 1
) AS c ON true;




WITH stale AS (
  SELECT pid
  FROM passage_passage_vector_clusters
  WHERE epoch = 2
  ORDER BY pid
  LIMIT 1000            -- batch size; adjust as needed
),
latest AS (
  SELECT max(epoch) AS e
  FROM passage_passage_vector_centroid
)
UPSERT INTO passage_passage_vector_clusters (pid, epoch, cluster_id)
SELECT s.pid,
       l.e,
       c.id
FROM stale AS s
JOIN passage AS p
  ON p.pid = s.pid
CROSS JOIN latest AS l
JOIN LATERAL (
  SELECT id
  FROM passage_passage_vector_centroid
  WHERE epoch = l.e
  ORDER BY l2_distance(p.passage_vector, centroid)
  LIMIT 1
) AS c ON true;


CLEANUP AFTERWARDS

DELETE
FROM passage_passage_vector_centroid
WHERE epoch = 2;

DELETE
FROM passage_passage_vector_centroid AS c
WHERE epoch = 2
  AND NOT EXISTS (
    SELECT 1
    FROM passage_passage_vector_clusters AS cl
    WHERE cl.epoch = c.epoch
  );



Update with cleanup as a transaction

BEGIN;

-- remap a batch of 10000 rows from epoch X
WITH stale AS (
  SELECT pid
  FROM passage_passage_vector_clusters
  WHERE epoch = $EPOCH
  ORDER BY pid
  LIMIT 10000
)
, latest AS (
  SELECT max(epoch) AS e
  FROM passage_passage_vector_centroid
)
UPSERT INTO passage_passage_vector_clusters (pid, epoch, cluster_id)
SELECT s.pid, l.e, c.id
FROM stale AS s
JOIN passage AS p
  ON p.pid = s.pid
CROSS JOIN latest AS l
JOIN LATERAL (
  SELECT id
  FROM passage_passage_vector_centroid
  WHERE epoch = l.e
  ORDER BY l2_distance(p.passage_vector, centroid)
  LIMIT 1
) AS c ON true;

-- then clear just those PIDs out of the stale epoch
DELETE FROM passage_passage_vector_clusters
WHERE epoch = $EPOCH
  AND pid IN (SELECT pid FROM stale);

COMMIT;
